{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeuRLtW2Qvqcc3uyr/hJH7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **NOTEBOOK 00: PROJECT SETUP & FOLDER STRUCTURE GENERATOR**\n","\n","Purpose: Initialize the complete project directory structure for the\n","         Clinical Notes Q&A System on Google Drive\n","\n","This notebook creates:\n","  - All necessary folders for the MLOps pipeline\n","  - README files with descriptions\n","  - Configuration templates\n","  - .gitignore preparation\n","\n","Output: Complete project structure ready for development\n","\n","Author: Clinical Notes QA System Project\n","Date: January 2026"],"metadata":{"id":"cCpJ9IW78RsP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d78EcHZ8MnG","executionInfo":{"status":"ok","timestamp":1768670324199,"user_tz":-330,"elapsed":15825,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"050e13fc-79e8-4cfb-b87d-48f7a610acfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","âœ… Google Drive mounted successfully\n","ğŸ“ Project will be created at: /content/drive/MyDrive/Colab_Notebooks/LLMs/clinical_notes_qa_project\n"]}],"source":["from google.colab import drive\n","import os\n","from datetime import datetime\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define project root\n","PROJECT_ROOT = \"/content/drive/MyDrive/Colab_Notebooks/LLMs/clinical_notes_qa_project\"\n","\n","print(f\"âœ… Google Drive mounted successfully\")\n","print(f\"ğŸ“ Project will be created at: {PROJECT_ROOT}\")"]},{"cell_type":"code","source":["# Complete project folder structure\n","FOLDER_STRUCTURE = {\n","    \"01_data_generation\": {\n","        \"outputs\": {\n","            \"raw_clinical_notes\": {},\n","        }\n","    },\n","    \"02_data_preprocessing\": {\n","        \"outputs\": {\n","            \"deidentified_notes\": {},\n","            \"deidentification_logs\": {},\n","        }\n","    },\n","    \"03_knowledge_base\": {\n","        \"outputs\": {\n","            \"embeddings\": {},\n","            \"vector_store\": {},\n","        }\n","    },\n","    \"04_retrieval_system\": {\n","        \"outputs\": {\n","            \"retrieval_metrics\": {},\n","        }\n","    },\n","    \"05_qa_generation\": {\n","        \"outputs\": {\n","            \"qa_pairs_validation\": {},\n","        }\n","    },\n","    \"06_mlops_artifacts\": {\n","        \"outputs\": {\n","            \"model_registry\": {},\n","            \"experiment_logs\": {},\n","            \"performance_metrics\": {},\n","        }\n","    },\n","    \"07_inference_demo\": {\n","        \"outputs\": {\n","            \"conversation_logs\": {},\n","        }\n","    },\n","    \"08_evaluation\": {\n","        \"outputs\": {\n","            \"test_results\": {},\n","        }\n","    },\n","    \"config\": {},\n","    \"utils\": {},\n","    \"docs\": {},\n","}\n","\n","print(\"âœ… Folder structure defined\")\n","print(f\"ğŸ“Š Total main directories: {len(FOLDER_STRUCTURE)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVdSNNjy84z2","executionInfo":{"status":"ok","timestamp":1768670324201,"user_tz":-330,"elapsed":10,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"28d934da-366c-4711-f490-2d92311aa950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Folder structure defined\n","ğŸ“Š Total main directories: 11\n"]}]},{"cell_type":"code","source":["def create_folder_structure(base_path, structure, level=0):\n","    \"\"\"Recursively create folder structure\"\"\"\n","    folders_created = []\n","\n","    for folder_name, subfolders in structure.items():\n","        folder_path = os.path.join(base_path, folder_name)\n","\n","        # Create folder if it doesn't exist\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path, exist_ok=True)\n","            folders_created.append(folder_path)\n","            indent = \"  \" * level\n","            print(f\"{indent}ğŸ“ Created: {folder_name}/\")\n","\n","        # Recursively create subfolders\n","        if subfolders:\n","            sub_created = create_folder_structure(folder_path, subfolders, level + 1)\n","            folders_created.extend(sub_created)\n","\n","    return folders_created\n","\n","print(\"=\" * 80)\n","print(\"CREATING FOLDER STRUCTURE\")\n","print(\"=\" * 80)\n","print()\n","\n","# Create the complete structure\n","created_folders = create_folder_structure(PROJECT_ROOT, FOLDER_STRUCTURE)\n","\n","print()\n","print(f\"âœ… Created {len(created_folders)} folders successfully\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cL7SokqJ89Uk","executionInfo":{"status":"ok","timestamp":1768670325288,"user_tz":-330,"elapsed":1092,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"501a9dd8-e791-4d58-8a51-aa133e9afeb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CREATING FOLDER STRUCTURE\n","================================================================================\n","\n","ğŸ“ Created: 01_data_generation/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: raw_clinical_notes/\n","ğŸ“ Created: 02_data_preprocessing/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: deidentified_notes/\n","    ğŸ“ Created: deidentification_logs/\n","ğŸ“ Created: 03_knowledge_base/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: embeddings/\n","    ğŸ“ Created: vector_store/\n","ğŸ“ Created: 04_retrieval_system/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: retrieval_metrics/\n","ğŸ“ Created: 05_qa_generation/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: qa_pairs_validation/\n","ğŸ“ Created: 06_mlops_artifacts/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: model_registry/\n","    ğŸ“ Created: experiment_logs/\n","    ğŸ“ Created: performance_metrics/\n","ğŸ“ Created: 07_inference_demo/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: conversation_logs/\n","ğŸ“ Created: 08_evaluation/\n","  ğŸ“ Created: outputs/\n","    ğŸ“ Created: test_results/\n","ğŸ“ Created: config/\n","ğŸ“ Created: utils/\n","ğŸ“ Created: docs/\n","\n","âœ… Created 31 folders successfully\n"]}]},{"cell_type":"code","source":["main_readme_content = \"\"\"# Clinical Notes Q&A System\n","## Personalized Patient Q&A using GenAI + MLOps\n","\n","### ğŸ¯ Project Overview\n","This project builds a production-level Q&A system that allows patients to interact with their clinical notes using natural language queries. The system ensures:\n","- **Patient data isolation**: Each patient only accesses their own records\n","- **Intelligent synthesis**: Not just chunk retrieval, but reasoned answers\n","- **Citation transparency**: Every answer cites source clinical notes\n","- **Privacy-first**: De-identification pipeline before processing\n","\n","### ğŸ—ï¸ Architecture\n","```\n","Synthetic Data â†’ De-identification â†’ Embedding Generation â†’ Vector Store\n","                                                                 â†“\n","Patient Query â†’ Filtered Retrieval â†’ LLM Reasoning â†’ Cited Answer\n","```\n","\n","### ğŸ“‚ Project Structure\n","- `01_data_generation/` - Synthetic clinical notes generation\n","- `02_data_preprocessing/` - De-identification and data cleaning\n","- `03_knowledge_base/` - Embedding generation and vector store setup\n","- `04_retrieval_system/` - Patient-specific retrieval logic\n","- `05_qa_generation/` - RAG pipeline with LLM integration\n","- `06_mlops_artifacts/` - Model versioning, experiment tracking, monitoring\n","- `07_inference_demo/` - Interactive patient Q&A chatbot\n","- `08_evaluation/` - End-to-end testing and evaluation\n","- `config/` - Configuration files for models, prompts, patients\n","- `utils/` - Reusable Python utilities\n","- `docs/` - Documentation and guides\n","\n","### ğŸš€ Technology Stack (100% Free)\n","- **LLM**: Google Gemini 2.0 Flash (Free API)\n","- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2\n","- **Vector Store**: ChromaDB (local)\n","- **De-identification**: Presidio (open-source)\n","- **Development**: Google Colab + Google Drive\n","\n","### ğŸ“Š MLOps Features\n","- Data versioning and lineage tracking\n","- Experiment logging (hyperparameters, metrics)\n","- Model registry with versioning\n","- Retrieval and generation metrics\n","- Privacy compliance auditing\n","\n","### ğŸ”’ Privacy & Safety\n","- Synthetic data only (no real patient information)\n","- De-identification validation at every step\n","- Patient isolation guarantees (zero cross-contamination)\n","- Citation transparency for all answers\n","\n","### ğŸ“ Getting Started\n","1. Run `00_project_setup.ipynb` to create folder structure\n","2. Run `01_synthetic_clinical_notes_generator.ipynb` to generate data\n","3. Follow notebooks sequentially (02 â†’ 03 â†’ ... â†’ 08)\n","4. Use `07_inference_demo.ipynb` for interactive Q&A\n","\n","### ğŸ“… Project Timeline\n","- **Created**: January 2026\n","- **Data Version**: v1.0\n","- **Status**: Development Phase (Google Drive + Colab)\n","- **Next Phase**: GitHub migration\n","\n","### ğŸ‘¤ Author\n","Clinical Notes Q&A System Project\n","\n","---\n","*This project demonstrates production-level MLOps practices for healthcare GenAI applications.*\n","\"\"\"\n","\n","readme_path = f\"{PROJECT_ROOT}/README.md\"\n","with open(readme_path, 'w', encoding='utf-8') as f:\n","    f.write(main_readme_content)\n","\n","print(f\"âœ… Created main README.md at: {readme_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERu0LTUC8_LO","executionInfo":{"status":"ok","timestamp":1768670325305,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"661b0e20-c918-4df9-c496-1996e7c0ca7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created main README.md at: /content/drive/MyDrive/Colab_Notebooks/LLMs/clinical_notes_qa_project/README.md\n"]}]},{"cell_type":"code","source":["# README content for each notebook directory\n","notebook_readmes = {\n","    \"01_data_generation\": \"\"\"# 01 - Data Generation\n","\n","## Purpose\n","Generate synthetic clinical notes for 10 patients to simulate realistic EHR data.\n","\n","## Notebooks\n","- `synthetic_clinical_notes_generator.ipynb` - Main data generation notebook\n","\n","## Outputs\n","- `raw_clinical_notes/` - Individual patient folders with clinical notes\n","- `patient_metadata.json` - Patient demographics and visit information\n","- `generation_summary.csv` - Statistical summary of generated data\n","- `mlops_generation_log.json` - Reproducibility tracking\n","\n","## Key Features\n","- 5 medical conditions (Diabetes, Hypertension, Asthma, CKD, Hyperlipidemia)\n","- 3-5 visits per patient over 2 years\n","- Realistic medications, lab values, and clinical assessments\n","- Reproducible generation (seed=42)\n","\"\"\",\n","\n","    \"02_data_preprocessing\": \"\"\"# 02 - Data Preprocessing\n","\n","## Purpose\n","De-identify clinical notes and validate data quality before downstream processing.\n","\n","## Notebooks\n","- `deidentification_pipeline.ipynb` - Remove PHI (names, dates, etc.)\n","- `quality_validation.ipynb` - Validate de-identification completeness\n","\n","## Outputs\n","- `deidentified_notes/` - Sanitized clinical notes\n","- `deidentification_logs/` - What was redacted and confidence scores\n","\n","## Key Features\n","- Presidio-based PHI detection\n","- Pattern-based entity removal\n","- Validation metrics (recall, precision)\n","- Compliance logging for audit trails\n","\"\"\",\n","\n","    \"03_knowledge_base\": \"\"\"# 03 - Knowledge Base Construction\n","\n","## Purpose\n","Convert clinical notes into embeddings and build patient-specific vector store.\n","\n","## Notebooks\n","- `embedding_generation.ipynb` - Chunk notes and generate embeddings\n","- `vector_store_setup.ipynb` - Initialize ChromaDB with patient metadata\n","\n","## Outputs\n","- `embeddings/` - Patient-specific embedding files\n","- `vector_store/` - ChromaDB database with patient_id filters\n","- `chunking_config.json` - Chunking strategy parameters\n","\n","## Key Features\n","- Semantic chunking (preserves context)\n","- Patient_id metadata tagging\n","- Embedding model versioning\n","- Vector store configuration tracking\n","\"\"\",\n","\n","    \"04_retrieval_system\": \"\"\"# 04 - Retrieval System\n","\n","## Purpose\n","Build and evaluate patient-specific retrieval with strict data isolation.\n","\n","## Notebooks\n","- `patient_specific_retriever.ipynb` - Implement filtered retrieval\n","- `retrieval_evaluation.ipynb` - Measure Hit@K, MRR, patient leakage\n","\n","## Outputs\n","- `retrieval_metrics/` - Performance metrics per patient\n","\n","## Key Features\n","- Patient_id filtering (zero cross-contamination)\n","- Top-K retrieval with re-ranking\n","- Retrieval quality metrics\n","- Patient isolation testing\n","\"\"\",\n","\n","    \"05_qa_generation\": \"\"\"# 05 - Q&A Generation\n","\n","## Purpose\n","Integrate LLM with retrieval to generate cited, synthesized answers.\n","\n","## Notebooks\n","- `llm_integration.ipynb` - Set up Gemini API\n","- `rag_pipeline.ipynb` - Build end-to-end RAG system\n","- `answer_grading.ipynb` - Evaluate answer quality\n","\n","## Outputs\n","- `qa_pairs_validation/` - Ground truth Q&A for testing\n","\n","## Key Features\n","- Prompt engineering for medical Q&A\n","- Citation extraction from retrieved chunks\n","- Answer synthesis (not regurgitation)\n","- Faithfulness and relevance metrics\n","\"\"\",\n","\n","    \"06_mlops_artifacts\": \"\"\"# 06 - MLOps Artifacts\n","\n","## Purpose\n","Track experiments, version models, and monitor system performance.\n","\n","## Notebooks\n","- `model_versioning.ipynb` - Version embeddings and LLMs\n","- `experiment_tracking.ipynb` - Log hyperparameters and metrics\n","- `monitoring_dashboard.ipynb` - Visualize performance over time\n","\n","## Outputs\n","- `model_registry/` - Model versions and metadata\n","- `experiment_logs/` - Experiment tracking data\n","- `performance_metrics/` - System performance dashboards\n","\n","## Key Features\n","- Model lineage tracking\n","- Hyperparameter logging\n","- Performance metric visualization\n","- Reproducibility guarantees\n","\"\"\",\n","\n","    \"07_inference_demo\": \"\"\"# 07 - Inference Demo\n","\n","## Purpose\n","Interactive patient Q&A chatbot for testing the complete system.\n","\n","## Notebooks\n","- `patient_qa_chatbot.ipynb` - Gradio-based interactive interface\n","\n","## Outputs\n","- `conversation_logs/` - User interaction logs for analysis\n","\n","## Key Features\n","- Patient selection dropdown\n","- Real-time Q&A with citations\n","- Conversation history\n","- Error handling and fallbacks\n","\"\"\",\n","\n","    \"08_evaluation\": \"\"\"# 08 - Evaluation\n","\n","## Purpose\n","Comprehensive end-to-end testing and privacy auditing.\n","\n","## Notebooks\n","- `end_to_end_testing.ipynb` - Test all 10 patients with ground truth Q&A\n","- `privacy_audit.ipynb` - Verify patient data isolation\n","\n","## Outputs\n","- `test_results/` - Evaluation reports and metrics\n","\n","## Key Features\n","- Automated test suite\n","- Patient leakage detection\n","- Answer quality metrics (RAGAS)\n","- Privacy compliance validation\n","\"\"\"\n","}\n","\n","# Create README for each notebook directory\n","for folder, content in notebook_readmes.items():\n","    readme_path = f\"{PROJECT_ROOT}/{folder}/README.md\"\n","    with open(readme_path, 'w', encoding='utf-8') as f:\n","        f.write(content)\n","    print(f\"âœ… Created README for: {folder}\")\n","\n","print(f\"\\nâœ… Created {len(notebook_readmes)} notebook READMEs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-23bYyV9Gdd","executionInfo":{"status":"ok","timestamp":1768670325485,"user_tz":-330,"elapsed":178,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"149e03fa-38b0-4f53-b30f-bce035125c8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created README for: 01_data_generation\n","âœ… Created README for: 02_data_preprocessing\n","âœ… Created README for: 03_knowledge_base\n","âœ… Created README for: 04_retrieval_system\n","âœ… Created README for: 05_qa_generation\n","âœ… Created README for: 06_mlops_artifacts\n","âœ… Created README for: 07_inference_demo\n","âœ… Created README for: 08_evaluation\n","\n","âœ… Created 8 notebook READMEs\n"]}]},{"cell_type":"code","source":["# Create model configuration template\n","model_config = \"\"\"# Model Configuration\n","# This file defines all models used in the pipeline\n","\n","embedding_model:\n","  name: \"sentence-transformers/all-MiniLM-L6-v2\"\n","  dimension: 384\n","  max_sequence_length: 256\n","  device: \"cpu\"  # Change to \"cuda\" if GPU available\n","\n","llm_model:\n","  provider: \"google\"\n","  model_name: \"gemini-2.0-flash-exp\"\n","  temperature: 0.3\n","  max_tokens: 1000\n","  top_p: 0.95\n","\n","vector_store:\n","  type: \"chromadb\"\n","  collection_name: \"clinical_notes\"\n","  distance_metric: \"cosine\"\n","\n","retrieval:\n","  top_k: 5\n","  similarity_threshold: 0.7\n","  rerank: false\n","\n","chunking:\n","  strategy: \"semantic\"  # Options: semantic, fixed, recursive\n","  chunk_size: 512\n","  chunk_overlap: 50\n","\"\"\"\n","\n","model_config_path = f\"{PROJECT_ROOT}/config/model_config.yaml\"\n","with open(model_config_path, 'w', encoding='utf-8') as f:\n","    f.write(model_config)\n","\n","print(f\"âœ… Created: config/model_config.yaml\")\n","\n","# Create prompt templates\n","prompt_templates = \"\"\"# Prompt Templates for Q&A System\n","\n","qa_system_prompt: |\n","  You are a medical assistant helping patients understand their clinical notes.\n","\n","  CRITICAL RULES:\n","  1. Only use information from the provided clinical notes\n","  2. Cite the specific note and date for every claim\n","  3. If information is not available, clearly state that\n","  4. Explain medical terms in patient-friendly language\n","  5. Never make up information or use external medical knowledge\n","\n","  FORMAT:\n","  - Provide a clear, direct answer\n","  - Include citations: [Note from YYYY-MM-DD]\n","  - Explain the \"why\" behind medical decisions\n","\n","qa_user_prompt_template: |\n","  PATIENT CLINICAL NOTES:\n","  {retrieved_chunks}\n","\n","  PATIENT QUESTION:\n","  {user_question}\n","\n","  Please answer the question using ONLY the information from the clinical notes above.\n","  Cite specific notes and explain your reasoning.\n","\n","synthesis_prompt: |\n","  Given multiple pieces of information from different clinical visits, synthesize\n","  a comprehensive answer that:\n","  1. Combines relevant information chronologically\n","  2. Highlights trends or changes over time\n","  3. Cites each source note\n","  4. Explains clinical reasoning\n","\"\"\"\n","\n","prompt_templates_path = f\"{PROJECT_ROOT}/config/prompt_templates.yaml\"\n","with open(prompt_templates_path, 'w', encoding='utf-8') as f:\n","    f.write(prompt_templates)\n","\n","print(f\"âœ… Created: config/prompt_templates.yaml\")\n","\n","# Create patient config placeholder\n","patient_config = \"\"\"# Patient Configuration\n","# This file will be auto-generated after data generation\n","\n","patients:\n","  # Will be populated by notebook 01\n","  # Example:\n","  # patient_001:\n","  #   name: \"John Doe\"\n","  #   conditions: [\"Type 2 Diabetes\", \"Hypertension\"]\n","  #   num_visits: 4\n","\"\"\"\n","\n","patient_config_path = f\"{PROJECT_ROOT}/config/patient_config.yaml\"\n","with open(patient_config_path, 'w', encoding='utf-8') as f:\n","    f.write(patient_config)\n","\n","print(f\"âœ… Created: config/patient_config.yaml\")\n","\n","print(\"\\nâœ… All configuration templates created\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbF7HVR59NKI","executionInfo":{"status":"ok","timestamp":1768670325490,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"6b804fb0-fe72-47cd-bf85-b050e250165d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: config/model_config.yaml\n","âœ… Created: config/prompt_templates.yaml\n","âœ… Created: config/patient_config.yaml\n","\n","âœ… All configuration templates created\n"]}]},{"cell_type":"code","source":["gitignore_content = \"\"\"# Python\n","__pycache__/\n","*.py[cod]\n","*$py.class\n","*.so\n",".Python\n","env/\n","venv/\n","*.egg-info/\n","\n","# Jupyter Notebooks\n",".ipynb_checkpoints/\n","*-checkpoint.ipynb\n","\n","# Data files (don't commit large datasets)\n","*.csv\n","*.json\n","*.txt\n","*.pkl\n","*.parquet\n","\n","# Model files\n","*.bin\n","*.h5\n","*.onnx\n","*.pt\n","\n","# Vector stores\n","*.db\n","*.sqlite\n","chroma_db/\n","\n","# Environment\n",".env\n",".env.local\n","\n","# Google Colab\n",".config/\n","\n","# OS\n",".DS_Store\n","Thumbs.db\n","\n","# MLOps artifacts\n","mlruns/\n","experiment_logs/\n","\n","# Outputs (keep structure, ignore contents)\n","outputs/raw_clinical_notes/*\n","!outputs/raw_clinical_notes/.gitkeep\n","outputs/deidentified_notes/*\n","!outputs/deidentified_notes/.gitkeep\n","outputs/embeddings/*\n","!outputs/embeddings/.gitkeep\n","outputs/vector_store/*\n","!outputs/vector_store/.gitkeep\n","\n","# BUT keep README files\n","!README.md\n","!*/README.md\n","\"\"\"\n","\n","gitignore_path = f\"{PROJECT_ROOT}/.gitignore\"\n","with open(gitignore_path, 'w', encoding='utf-8') as f:\n","    f.write(gitignore_content)\n","\n","print(f\"âœ… Created: .gitignore\")\n","print(\"   (Ready for GitHub migration)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4hEyYuF9Ve-","executionInfo":{"status":"ok","timestamp":1768670325533,"user_tz":-330,"elapsed":42,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"369876c6-635b-4ebf-8802-d5ea394ee36b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: .gitignore\n","   (Ready for GitHub migration)\n"]}]},{"cell_type":"code","source":["requirements_content = \"\"\"# Clinical Notes Q&A System - Requirements\n","# Install with: pip install -r requirements.txt\n","\n","# Core ML/AI\n","sentence-transformers==2.2.2\n","chromadb==0.4.22\n","google-generativeai==0.3.2\n","\n","# Data Processing\n","pandas==2.1.4\n","numpy==1.24.3\n","faker==22.0.0\n","\n","# NLP & Text Processing\n","presidio-analyzer==2.2.33\n","presidio-anonymizer==2.2.33\n","spacy==3.7.2\n","\n","# Utilities\n","python-dotenv==1.0.0\n","pyyaml==6.0.1\n","tqdm==4.66.1\n","\n","# Evaluation\n","datasets==2.16.1\n","rouge-score==0.1.2\n","\n","# Visualization (optional)\n","matplotlib==3.8.2\n","seaborn==0.13.1\n","\n","# UI (for demo)\n","gradio==4.16.0\n","\n","# Note: For Colab, most packages are pre-installed\n","# Only install missing packages as needed\n","\"\"\"\n","\n","requirements_path = f\"{PROJECT_ROOT}/requirements.txt\"\n","with open(requirements_path, 'w', encoding='utf-8') as f:\n","    f.write(requirements_content)\n","\n","print(f\"âœ… Created: requirements.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGz2Gbyo9Xsq","executionInfo":{"status":"ok","timestamp":1768670325537,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"7b5795d4-775e-4d63-b57a-957cd0e9c18c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: requirements.txt\n"]}]},{"cell_type":"code","source":["# Create placeholder Python files in utils/\n","utils_files = {\n","    \"__init__.py\": '\"\"\"Utility modules for Clinical Notes Q&A System\"\"\"',\n","\n","    \"deidentification_utils.py\": '''\"\"\"\n","De-identification utilities for clinical notes.\n","\n","Functions:\n","- remove_phi(): Remove protected health information\n","- validate_deidentification(): Check for PHI leakage\n","\"\"\"\n","\n","def remove_phi(text):\n","    \"\"\"Remove PHI from clinical text\"\"\"\n","    # TODO: Implement in notebook 02\n","    pass\n","\n","def validate_deidentification(original, deidentified):\n","    \"\"\"Validate PHI removal completeness\"\"\"\n","    # TODO: Implement in notebook 02\n","    pass\n","''',\n","\n","    \"embedding_utils.py\": '''\"\"\"\n","Embedding generation utilities.\n","\n","Functions:\n","- generate_embeddings(): Create embeddings from text chunks\n","- load_embedding_model(): Initialize embedding model\n","\"\"\"\n","\n","def generate_embeddings(texts, model):\n","    \"\"\"Generate embeddings for text chunks\"\"\"\n","    # TODO: Implement in notebook 03\n","    pass\n","\n","def load_embedding_model(model_name):\n","    \"\"\"Load embedding model\"\"\"\n","    # TODO: Implement in notebook 03\n","    pass\n","''',\n","\n","    \"retrieval_utils.py\": '''\"\"\"\n","Retrieval utilities for patient-specific search.\n","\n","Functions:\n","- retrieve_patient_chunks(): Get relevant chunks for a patient\n","- filter_by_patient(): Ensure patient data isolation\n","\"\"\"\n","\n","def retrieve_patient_chunks(query, patient_id, vector_store, top_k=5):\n","    \"\"\"Retrieve relevant chunks for specific patient\"\"\"\n","    # TODO: Implement in notebook 04\n","    pass\n","\n","def filter_by_patient(results, patient_id):\n","    \"\"\"Filter results to ensure patient isolation\"\"\"\n","    # TODO: Implement in notebook 04\n","    pass\n","''',\n","\n","    \"llm_utils.py\": '''\"\"\"\n","LLM interaction utilities.\n","\n","Functions:\n","- call_llm(): Make LLM API calls\n","- format_prompt(): Format prompts with templates\n","- extract_citations(): Extract citation references\n","\"\"\"\n","\n","def call_llm(prompt, model_config):\n","    \"\"\"Call LLM API with prompt\"\"\"\n","    # TODO: Implement in notebook 05\n","    pass\n","\n","def format_prompt(template, context, question):\n","    \"\"\"Format prompt using template\"\"\"\n","    # TODO: Implement in notebook 05\n","    pass\n","\n","def extract_citations(response, chunks):\n","    \"\"\"Extract and validate citations\"\"\"\n","    # TODO: Implement in notebook 05\n","    pass\n","''',\n","\n","    \"evaluation_utils.py\": '''\"\"\"\n","Evaluation metrics and utilities.\n","\n","Functions:\n","- calculate_retrieval_metrics(): Hit@K, MRR\n","- calculate_answer_metrics(): Faithfulness, relevance\n","- check_patient_leakage(): Verify data isolation\n","\"\"\"\n","\n","def calculate_retrieval_metrics(retrieved, ground_truth):\n","    \"\"\"Calculate retrieval performance metrics\"\"\"\n","    # TODO: Implement in notebook 08\n","    pass\n","\n","def calculate_answer_metrics(answer, ground_truth, retrieved_chunks):\n","    \"\"\"Calculate answer quality metrics\"\"\"\n","    # TODO: Implement in notebook 08\n","    pass\n","\n","def check_patient_leakage(retrieval_results, patient_id):\n","    \"\"\"Verify no data leakage across patients\"\"\"\n","    # TODO: Implement in notebook 08\n","    pass\n","'''\n","}\n","\n","for filename, content in utils_files.items():\n","    filepath = f\"{PROJECT_ROOT}/utils/{filename}\"\n","    with open(filepath, 'w', encoding='utf-8') as f:\n","        f.write(content)\n","    print(f\"âœ… Created: utils/{filename}\")\n","\n","print(f\"\\nâœ… Created {len(utils_files)} utility file stubs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"980oQiR_9a7K","executionInfo":{"status":"ok","timestamp":1768670325600,"user_tz":-330,"elapsed":62,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"c64449c5-978d-4d32-e064-73303287427a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: utils/__init__.py\n","âœ… Created: utils/deidentification_utils.py\n","âœ… Created: utils/embedding_utils.py\n","âœ… Created: utils/retrieval_utils.py\n","âœ… Created: utils/llm_utils.py\n","âœ… Created: utils/evaluation_utils.py\n","\n","âœ… Created 6 utility file stubs\n"]}]},{"cell_type":"code","source":["# Create project documentation\n","architecture_doc = \"\"\"# System Architecture\n","\n","## Overview\n","The Clinical Notes Q&A System uses a Retrieval-Augmented Generation (RAG) architecture with strict patient data isolation.\n","\n","## Architecture Diagram\n","```\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ Patient Query   â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","         â”‚\n","         â–¼\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ Patient ID Selection    â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","         â”‚\n","         â–¼\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ Vector Store Retrieval  â”‚\n","â”‚ (Filtered by patient_id)â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","         â”‚\n","         â–¼\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ Retrieved Chunks (Top-K)â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","         â”‚\n","         â–¼\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ LLM Reasoning           â”‚\n","â”‚ (Gemini 2.0 Flash)      â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","         â”‚\n","         â–¼\n","â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","â”‚ Cited Answer            â”‚\n","â”‚ (with source notes)     â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","```\n","\n","## Components\n","\n","### 1. Data Layer\n","- **Synthetic Data**: Realistic clinical notes\n","- **De-identification**: PHI removal pipeline\n","- **Storage**: Google Drive (dev), GitHub (production)\n","\n","### 2. Knowledge Base Layer\n","- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2\n","- **Vector Store**: ChromaDB with patient_id metadata\n","- **Chunking**: Semantic chunking (512 tokens)\n","\n","### 3. Retrieval Layer\n","- **Query Encoding**: Same embedding model\n","- **Filtering**: Strict patient_id filter (metadata)\n","- **Re-ranking**: Similarity threshold + Top-K\n","\n","### 4. Generation Layer\n","- **LLM**: Google Gemini 2.0 Flash (free API)\n","- **Prompt Engineering**: System + context + query\n","- **Post-processing**: Citation extraction\n","\n","### 5. MLOps Layer\n","- **Versioning**: Models, data, configurations\n","- **Monitoring**: Retrieval metrics, answer quality\n","- **Evaluation**: Automated testing pipeline\n","\n","## Data Flow\n","1. Patient uploads clinical notes (in real system)\n","2. Notes de-identified and chunked\n","3. Chunks embedded and stored with patient_id tag\n","4. User selects patient and asks question\n","5. Query embedded and retrieves patient-specific chunks\n","6. LLM synthesizes answer from chunks\n","7. Answer returned with citations\n","\n","## Privacy Guarantees\n","- Patient data tagged at ingestion\n","- Vector store queries filtered by patient_id\n","- Privacy audit tests for cross-patient leakage\n","- De-identification validation at every step\n","\"\"\"\n","\n","arch_doc_path = f\"{PROJECT_ROOT}/docs/architecture.md\"\n","os.makedirs(f\"{PROJECT_ROOT}/docs\", exist_ok=True)\n","with open(arch_doc_path, 'w', encoding='utf-8') as f:\n","    f.write(architecture_doc)\n","\n","print(f\"âœ… Created: docs/architecture.md\")\n","\n","# Create development guide\n","dev_guide = \"\"\"# Development Guide\n","\n","## Getting Started\n","\n","### Prerequisites\n","- Google Account (for Colab and Drive)\n","- Google Gemini API key (free tier)\n","- Basic Python knowledge\n","\n","### Setup\n","1. Run `00_project_setup.ipynb` to create folder structure\n","2. Run notebooks sequentially (01 â†’ 02 â†’ ... â†’ 08)\n","3. Each notebook saves outputs to Google Drive\n","4. Outputs from one notebook feed into the next\n","\n","## Development Workflow\n","\n","### Phase 1: Data Preparation (Notebooks 01-02)\n","1. Generate synthetic clinical notes\n","2. De-identify and validate data\n","3. Verify data quality\n","\n","### Phase 2: Knowledge Base (Notebooks 03-04)\n","1. Generate embeddings\n","2. Build vector store\n","3. Test retrieval with patient filtering\n","\n","### Phase 3: Q&A System (Notebooks 05-07)\n","1. Integrate LLM\n","2. Build RAG pipeline\n","3. Create interactive demo\n","\n","### Phase 4: Evaluation (Notebook 08)\n","1. End-to-end testing\n","2. Privacy audit\n","3. Performance metrics\n","\n","## Best Practices\n","\n","### Code Organization\n","- Keep notebooks focused on single tasks\n","- Extract reusable code to `utils/`\n","- Use configuration files for parameters\n","\n","### Data Management\n","- Version all datasets (v1.0, v1.1, etc.)\n","- Log data transformations\n","- Validate data at each step\n","\n","### MLOps\n","- Track all experiments\n","- Version models and embeddings\n","- Monitor system performance\n","\n","## Troubleshooting\n","\n","### Common Issues\n","- **Out of memory**: Reduce batch size in embeddings\n","- **Slow retrieval**: Reduce top_k or add similarity threshold\n","- **Poor answers**: Adjust prompt templates or increase context\n","\n","## Migration to GitHub\n","1. Clean notebooks (remove hardcoded paths)\n","2. Add requirements.txt\n","3. Update README with installation instructions\n","4. Test end-to-end on fresh environment\n","\"\"\"\n","\n","dev_guide_path = f\"{PROJECT_ROOT}/docs/development_guide.md\"\n","with open(dev_guide_path, 'w', encoding='utf-8') as f:\n","    f.write(dev_guide)\n","\n","print(f\"âœ… Created: docs/development_guide.md\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mobKgDPW9baK","executionInfo":{"status":"ok","timestamp":1768670325667,"user_tz":-330,"elapsed":50,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"73bf6f60-fbb2-447e-e70f-7583502d3619"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: docs/architecture.md\n","âœ… Created: docs/development_guide.md\n"]}]},{"cell_type":"code","source":["import json\n","\n","project_metadata = {\n","    \"project_name\": \"Clinical Notes Q&A System\",\n","    \"version\": \"1.0.0\",\n","    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n","    \"status\": \"development\",\n","    \"phase\": \"google_drive_colab\",\n","    \"description\": \"Personalized patient Q&A system using GenAI and MLOps best practices\",\n","    \"technology_stack\": {\n","        \"llm\": \"Google Gemini 2.0 Flash\",\n","        \"embeddings\": \"sentence-transformers/all-MiniLM-L6-v2\",\n","        \"vector_store\": \"ChromaDB\",\n","        \"deidentification\": \"Presidio\",\n","        \"development\": \"Google Colab + Google Drive\"\n","    },\n","    \"mlops_features\": [\n","        \"Data versioning\",\n","        \"Model registry\",\n","        \"Experiment tracking\",\n","        \"Performance monitoring\",\n","        \"Privacy auditing\"\n","    ],\n","    \"notebooks\": [\n","        \"00_project_setup\",\n","        \"01_synthetic_clinical_notes_generator\",\n","        \"02_deidentification_pipeline\",\n","        \"03_embedding_generation\",\n","        \"04_retrieval_system\",\n","        \"05_qa_generation\",\n","        \"06_mlops_artifacts\",\n","        \"07_inference_demo\",\n","        \"08_evaluation\"\n","    ],\n","    \"total_patients\": 10,\n","    \"conditions_covered\": [\n","        \"Type 2 Diabetes\",\n","        \"Hypertension\",\n","        \"Asthma\",\n","        \"Chronic Kidney Disease\",\n","        \"Hyperlipidemia\"\n","    ]\n","}\n","\n","metadata_path = f\"{PROJECT_ROOT}/project_metadata.json\"\n","with open(metadata_path, 'w', encoding='utf-8') as f:\n","    json.dump(project_metadata, f, indent=2)\n","\n","print(f\"âœ… Created: project_metadata.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCAb1hQt9d-R","executionInfo":{"status":"ok","timestamp":1768670325697,"user_tz":-330,"elapsed":29,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"b8f08406-dc9c-42e1-fea5-76b27f57c54d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: project_metadata.json\n"]}]},{"cell_type":"code","source":["def visualize_tree(path, prefix=\"\", is_last=True, max_depth=3, current_depth=0):\n","    \"\"\"Recursively visualize directory tree\"\"\"\n","    if current_depth >= max_depth:\n","        return\n","\n","    items = sorted(os.listdir(path))\n","    # Filter out hidden files\n","    items = [item for item in items if not item.startswith('.')]\n","\n","    for i, item in enumerate(items):\n","        is_last_item = (i == len(items) - 1)\n","        item_path = os.path.join(path, item)\n","\n","        # Print tree structure\n","        connector = \"â””â”€â”€ \" if is_last_item else \"â”œâ”€â”€ \"\n","        print(f\"{prefix}{connector}{item}\")\n","\n","        # Recurse for directories\n","        if os.path.isdir(item_path):\n","            extension = \"    \" if is_last_item else \"â”‚   \"\n","            visualize_tree(item_path, prefix + extension, is_last_item,\n","                          max_depth, current_depth + 1)\n","\n","print(\"=\" * 80)\n","print(\"PROJECT FOLDER STRUCTURE\")\n","print(\"=\" * 80)\n","print()\n","print(f\"clinical_notes_qa_project/\")\n","visualize_tree(PROJECT_ROOT, max_depth=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lGUTg7b9l2Z","executionInfo":{"status":"ok","timestamp":1768670325716,"user_tz":-330,"elapsed":17,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"e74db2c2-bd3e-42ee-b3f1-0b4021abd5c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","PROJECT FOLDER STRUCTURE\n","================================================================================\n","\n","clinical_notes_qa_project/\n","â”œâ”€â”€ 01_data_generation\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â””â”€â”€ raw_clinical_notes\n","â”œâ”€â”€ 02_data_preprocessing\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â”œâ”€â”€ deidentification_logs\n","â”‚       â””â”€â”€ deidentified_notes\n","â”œâ”€â”€ 03_knowledge_base\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â”œâ”€â”€ embeddings\n","â”‚       â””â”€â”€ vector_store\n","â”œâ”€â”€ 04_retrieval_system\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â””â”€â”€ retrieval_metrics\n","â”œâ”€â”€ 05_qa_generation\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â””â”€â”€ qa_pairs_validation\n","â”œâ”€â”€ 06_mlops_artifacts\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â”œâ”€â”€ experiment_logs\n","â”‚       â”œâ”€â”€ model_registry\n","â”‚       â””â”€â”€ performance_metrics\n","â”œâ”€â”€ 07_inference_demo\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â””â”€â”€ conversation_logs\n","â”œâ”€â”€ 08_evaluation\n","â”‚   â”œâ”€â”€ README.md\n","â”‚   â””â”€â”€ outputs\n","â”‚       â””â”€â”€ test_results\n","â”œâ”€â”€ README.md\n","â”œâ”€â”€ Untitled0.ipynb\n","â”œâ”€â”€ config\n","â”‚   â”œâ”€â”€ model_config.yaml\n","â”‚   â”œâ”€â”€ patient_config.yaml\n","â”‚   â””â”€â”€ prompt_templates.yaml\n","â”œâ”€â”€ docs\n","â”‚   â”œâ”€â”€ architecture.md\n","â”‚   â””â”€â”€ development_guide.md\n","â”œâ”€â”€ project_metadata.json\n","â”œâ”€â”€ requirements.txt\n","â””â”€â”€ utils\n","    â”œâ”€â”€ __init__.py\n","    â”œâ”€â”€ deidentification_utils.py\n","    â”œâ”€â”€ embedding_utils.py\n","    â”œâ”€â”€ evaluation_utils.py\n","    â”œâ”€â”€ llm_utils.py\n","    â””â”€â”€ retrieval_utils.py\n"]}]},{"cell_type":"code","source":["# Create template for future notebooks\n","notebook_template = '''\"\"\"\n","=============================================================================\n","NOTEBOOK XX: [NOTEBOOK NAME]\n","=============================================================================\n","\n","Purpose: [Brief description of what this notebook does]\n","\n","Inputs:\n","  - [List input files/directories]\n","\n","Outputs:\n","  - [List output files/directories]\n","\n","MLOps Tracking:\n","  - [What is being logged/versioned]\n","\n","Author: Clinical Notes QA System Project\n","Date: January 2026\n","=============================================================================\n","\"\"\"\n","\n","# Cell 1: Setup and Imports\n","import os\n","import json\n","from datetime import datetime\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","PROJECT_ROOT = \"/content/drive/MyDrive/clinical_notes_qa_project\"\n","print(f\"âœ… Google Drive mounted\")\n","print(f\"ğŸ“ Project root: {PROJECT_ROOT}\")\n","\n","# Cell 2: Load configuration\n","# TODO: Load relevant config files\n","\n","# Cell 3: Load previous outputs\n","# TODO: Load outputs from previous notebooks\n","\n","# Cell 4: Main processing\n","# TODO: Implement main logic\n","\n","# Cell 5: Save outputs\n","# TODO: Save results to outputs directory\n","\n","# Cell 6: MLOps logging\n","mlops_log = {\n","    \"notebook\": \"XX_notebook_name\",\n","    \"execution_timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","    \"version\": \"v1.0\",\n","    # TODO: Add relevant metrics\n","}\n","\n","# Save log\n","log_path = f\"{PROJECT_ROOT}/XX_notebook_dir/outputs/mlops_log.json\"\n","with open(log_path, 'w') as f:\n","    json.dump(mlops_log, f, indent=2)\n","\n","print(\"âœ… Notebook completed successfully\")\n","'''\n","\n","template_path = f\"{PROJECT_ROOT}/docs/notebook_template.txt\"\n","with open(template_path, 'w', encoding='utf-8') as f:\n","    f.write(notebook_template)\n","\n","print(f\"âœ… Created: docs/notebook_template.txt\")\n","print(\"   (Use this as a starting point for new notebooks)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnuengdV9puB","executionInfo":{"status":"ok","timestamp":1768670325774,"user_tz":-330,"elapsed":56,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"951baeae-6e2c-4715-c807-76af9c3bccb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Created: docs/notebook_template.txt\n","   (Use this as a starting point for new notebooks)\n"]}]},{"cell_type":"code","source":["# Count created files\n","total_folders = len(created_folders)\n","readme_files = len(notebook_readmes) + 1  # +1 for main README\n","config_files = 3  # model_config, prompt_templates, patient_config\n","util_files = len(utils_files)\n","doc_files = 3  # architecture, dev_guide, template\n","\n","total_files = readme_files + config_files + util_files + doc_files + 3  # +3 for .gitignore, requirements, metadata\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… PROJECT SETUP COMPLETED SUCCESSFULLY\")\n","print(\"=\" * 80)\n","\n","print(f\"\"\"\n","ğŸ“‚ Project Location: {PROJECT_ROOT}\n","\n","ğŸ“Š Setup Summary:\n","  âœ… {total_folders} folders created\n","  âœ… {total_files} files created\n","  âœ… Complete MLOps structure ready\n","  âœ… Configuration templates initialized\n","  âœ… Utility stubs prepared\n","  âœ… Documentation created\n","\n","ğŸ“ Key Directories Created:\n","  â”œâ”€â”€ 01_data_generation/          (Ready for synthetic data)\n","  â”œâ”€â”€ 02_data_preprocessing/        (De-identification pipeline)\n","  â”œâ”€â”€ 03_knowledge_base/            (Embeddings & vector store)\n","  â”œâ”€â”€ 04_retrieval_system/          (Patient-specific retrieval)\n","  â”œâ”€â”€ 05_qa_generation/             (RAG pipeline)\n","  â”œâ”€â”€ 06_mlops_artifacts/           (Experiment tracking)\n","  â”œâ”€â”€ 07_inference_demo/            (Interactive chatbot)\n","  â”œâ”€â”€ 08_evaluation/                (Testing & validation)\n","  â”œâ”€â”€ config/                       (Configuration files)\n","  â”œâ”€â”€ utils/                        (Reusable utilities)\n","  â””â”€â”€ docs/                         (Documentation)\n","\n","ğŸ“„ Configuration Files:\n","  âœ… model_config.yaml              (Model parameters)\n","  âœ… prompt_templates.yaml          (LLM prompts)\n","  âœ… patient_config.yaml            (Patient metadata)\n","\n","ğŸ“š Documentation:\n","  âœ… README.md                      (Project overview)\n","  âœ… architecture.md                (System design)\n","  âœ… development_guide.md           (How to develop)\n","  âœ… notebook_template.txt          (Template for new notebooks)\n","\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-twJEX-9rRj","executionInfo":{"status":"ok","timestamp":1768670408473,"user_tz":-330,"elapsed":13,"user":{"displayName":"Nishkala AI stuff","userId":"00738499590360371728"}},"outputId":"e2469c9b-0f2d-4171-b90a-71470f4e39b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","âœ… PROJECT SETUP COMPLETED SUCCESSFULLY\n","================================================================================\n","\n","ğŸ“‚ Project Location: /content/drive/MyDrive/Colab_Notebooks/LLMs/clinical_notes_qa_project\n","\n","ğŸ“Š Setup Summary:\n","  âœ… 31 folders created\n","  âœ… 24 files created\n","  âœ… Complete MLOps structure ready\n","  âœ… Configuration templates initialized\n","  âœ… Utility stubs prepared\n","  âœ… Documentation created\n","\n","ğŸ“ Key Directories Created:\n","  â”œâ”€â”€ 01_data_generation/          (Ready for synthetic data)\n","  â”œâ”€â”€ 02_data_preprocessing/        (De-identification pipeline)\n","  â”œâ”€â”€ 03_knowledge_base/            (Embeddings & vector store)\n","  â”œâ”€â”€ 04_retrieval_system/          (Patient-specific retrieval)\n","  â”œâ”€â”€ 05_qa_generation/             (RAG pipeline)\n","  â”œâ”€â”€ 06_mlops_artifacts/           (Experiment tracking)\n","  â”œâ”€â”€ 07_inference_demo/            (Interactive chatbot)\n","  â”œâ”€â”€ 08_evaluation/                (Testing & validation)\n","  â”œâ”€â”€ config/                       (Configuration files)\n","  â”œâ”€â”€ utils/                        (Reusable utilities)\n","  â””â”€â”€ docs/                         (Documentation)\n","\n","ğŸ“„ Configuration Files:\n","  âœ… model_config.yaml              (Model parameters)\n","  âœ… prompt_templates.yaml          (LLM prompts)\n","  âœ… patient_config.yaml            (Patient metadata)\n","\n","ğŸ“š Documentation:\n","  âœ… README.md                      (Project overview)\n","  âœ… architecture.md                (System design)\n","  âœ… development_guide.md           (How to develop)\n","  âœ… notebook_template.txt          (Template for new notebooks)\n","\n","\n"]}]}]}